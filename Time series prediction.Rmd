---
title: "Data Exploration"
author: "Gianluca Scuri"
date: "2022-12-11"
output:
  pdf_document: default
  html_document: default
---

# Time series forecast

## 0. Import

### Setup and useful functions

```{r}
set.seed(100)

Sys.setenv(TZ='GMT') # imposto la time zone

packages <- c("forecast", "KFAS", "xts", "fastDummies", "tsfknn", "MASS") # librerie

installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))
```

```{r}
stats <- function(actual,pred){
  rmse <- sqrt(mean((actual - pred)^2))
  mape <- mean(abs((actual - pred)/actual))*100
  mae <- mean(abs(actual - pred))
  cat("RMSE", rmse, "\nMAPE", mape, "\nMAE ", mae, "\n")
  return(c(rmse, mape, mae))
}

# Significativitá regressori
pars_test <- function(coef, var_coef){
  test <- (1-pnorm(abs(coef)/sqrt(diag(var_coef))))*2
  return(test)
}
```

```{r}
plot_pred <- function(pred, days=3){
  diff <- plot(data_xts[(val_index-144*5):(val_index+144*npred-1)]-pred) # serie storica - storica
  plot <- plot(data_xts[(val_index-144*5):(val_index+144*npred-1)], lwd=3) # serie storica e storica
  plot <- lines(pred, type = "l", col = "red", lwd=3)
  zoom <- plot(data_xts[(val_index+144*(npred-days)):(val_index+144*npred-1)], lwd=3) # zoom serie storica e storica
  zoom <- lines(pred, type = "l", col = "red", lwd=3)
  c(diff, plot, zoom)
}
```

### Loading data

```{r}
working_dir = dirname(rstudioapi::getSourceEditorContext()$path)
setwd(working_dir)

data <- read.csv("data2022_train.csv", colClasses=c("character", "numeric"))
```

```{r}
data_xts <- xts(data$y, as.POSIXct(data$X, format="%Y-%m-%d %H:%M:%S", tz="GMT"))
```

```{r}
periodicity(data_xts)
```

## 1. Data Exploration

```{r}
summary(data_xts)
```

### Plot time series

```{r}
plot(data_xts)
plot(apply.weekly(data_xts,FUN=mean))
plot(apply.monthly(data_xts,FUN=mean))
autoplot(mstl(data_xts))
```

```{r}
plot(data_xts[1:144])
plot(data_xts[1:144*21])
```

### Box-Cox transformation

```{r}
med <- tapply(data_xts, rep(1:334, each = 144), mean)
sds <- tapply(data_xts, rep(1:334, each = 144), sd)
plot(med, sds) # 334 dots -> one for each day
```

```{r}
bc <- boxcox(sds ~ med)
lambda <- bc$x[which.max(bc$y)]
lambda
```

```{r}
data_xts_bc <- (data_xts^lambda - 1) / lambda

med_bc <- tapply(data_xts_bc, rep(1:334, each = 144), mean)
sds_bc <- tapply(data_xts_bc, rep(1:334, each = 144), sd)
```

```{r}
plot(med_bc, sds_bc) # 334 dots -> one for each day
plot(med, sds) # 334 dots -> one for each day
plot(data_xts_bc)
```

### Detecting outliers

```{r}
plot(diff(data_xts,1))
plot(diff(data_xts_bc,1))
data_xts[diff(data_xts,1) < -5000 | diff(data_xts,1) > 5000] #|> index() |> as.Date()
```

```{r}
par(mfrow=c(2,2))
plot(data_xts["2017-01-14"], ylim=c(15000,50000), main='', yaxis.right = FALSE, major.ticks = "days", col="red")
plot(data_xts["2017-03-28"], ylim=c(15000,50000), main='', yaxis.right = FALSE, major.ticks = "days", col="red")
plot(data_xts["2017-04-20"], ylim=c(15000,50000), main='', yaxis.right = FALSE, major.ticks = "days", col="red")
plot(data_xts["2017-05-31"], ylim=c(15000,50000), main='', yaxis.right = FALSE, major.ticks = "days", col="red")
```

### Train, validation e test set

```{r}
tseq <- seq(from = index(data_xts[nrow(data_xts),])+600, length.out = 144*30, by = 600)
data_xts_complete <- c(data_xts, xts(rep(as.numeric(NA), length(tseq)), tseq))
cat(paste0("from: ", index(data_xts_complete[1]), "\nto:   ", index(data_xts_complete[nrow(data_xts_complete)])))
```

```{r}
npred <- 30 # numero di giorni da predire
small_date <- "2017-10-01 00:00:00"
small_index <- which(index(data_xts_complete) == small_date)
val_date <- "2017-11-01 00:00:00"
val_index <- which(index(data_xts_complete) == val_date)
test_date <- "2017-12-01 00:00:00"
test_index <- which(index(data_xts_complete) == test_date)
cat(paste0("small_index: ", small_index,"\nval_index:   ", val_index, "\ntest_index:  ", test_index))
```

```{r}
train <- data_xts_complete[1:(val_index-1)]
small <- data_xts_complete[small_index:(val_index-1)] # train piu veloce
val <- data_xts_complete[val_index:(val_index+144*npred-1),]
test <- data_xts_complete[test_index:nrow(data_xts_complete)]
cat(paste0("small: ", nrow(small), "\ntrain: ", nrow(train), "\nval:   ", nrow(val), "\ntest:  ", nrow(test)))
```

## 2. Data Modeling

```{r}
stats_results <- data.frame(matrix(nrow=0,ncol=4))
colnames(stats_results)<-c("Model", "RMSE", "MAPE", "MAE")
```

### ARIMA Models

-   Possibilita 1

    -   modellare settimana con dummy

    -   modellare giorno con differenza stagionale

-   Possibilita 2

    -   144 modelli per togliere stagionalita giornaliera

-   Possibilita 3

    -   24 modelli per togliere la stagionalita giornaliera usando la media dell'ora

```{r}
train_dummy <- fastDummies::dummy_cols(format(index(train), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(train_dummy) <- index(train)
colnames(train_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
train_dummy <- as.matrix(train_dummy)

val_dummy <- fastDummies::dummy_cols(format(index(val), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(val_dummy) <- index(val)
colnames(val_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
val_dummy <- as.matrix(val_dummy)

#train_arima <- cbind(train, train_dummy)
```

Stimo i parametri (p, q, d)

```{r}
ndiffs(train)
```

```{r}
train |> Acf(300)
train |> #[42000:length(train)]
  #diff() |>
  diff() |>
  #diff(144*7) |>
  diff(144) |>
  #autoplot()
  Acf(300)
#train[diff(diff(train, 144), 1) < -4000]
```

```{r}
train |> Pacf(300)
train |>
  diff(144) |>
  diff() |>
  Pacf(300)
```

```{r}
nsdiffs(train)
```

#### Mod 1

```{r}
#train <- (train^lambda - 1) / lambda
#data_xts <- (data_xts^lambda - 1) / lambda
```

```{r}
arima_mod1 <- function(train) {
  Arima(y = ts(train, freq = 144),
              order = c(0, 0, 0),
              seasonal = c(0, 1, 1),
              include.constant = FALSE)}
arima_mod1_train <- arima_mod1(train)
summary(arima_mod1_train)
```

```{r}
#arima_mod1.plot_diagnostics(figsize=c(7,5))
#plt.show()
```

```{r}
# plot(index(arima_mod1$residuals)/600/144, arima_mod1$residuals, type='l', xlab='Day', ylab='Residual')
```

```{r}
arima_pred1 <- forecast(arima_mod1_train, 144*npred)
plot(arima_pred1)
#abline(v=val_index*600)

arima_pred1 <- xts(arima_pred1$mean, index(val))
```

```{r}
plot_pred(arima_pred1)

stats_results[nrow(stats_results) + 1,] <- c("arima_mod1", stats(val, arima_pred1))
```

#### Mod 2

```{r}
arima_mod2 <- function(train) {
  Arima(y = ts(train, freq = 144),
              order = c(0, 1, 1),
              seasonal = c(0, 1, 1),
              include.constant = FALSE)}
arima_mod2_train <- arima_mod2(train)
summary(arima_mod2_train)
```

```{r}
arima_pred2 <- forecast(arima_mod2_train, 144*npred)
plot(arima_pred2)
abline(v=val_index*600)

arima_pred2 <- xts(arima_pred2$mean, index(val))
```

```{r}
plot_pred(arima_pred2)

stats_results[nrow(stats_results) + 1,] <- c("arima_mod2", stats(val, arima_pred2))
```

#### Mod 3

```{r}
arima_mod3 <- function(train) {
  Arima(y = ts(train, freq = 144),
              order = c(2, 1, 0),
              seasonal = c(0, 1, 1),
              include.constant = FALSE)}
arima_mod3_train <- arima_mod3(train)
summary(arima_mod3_train)
```

```{r}
arima_pred3 <- forecast(arima_mod3_train,
                  144*npred)
plot(arima_pred3)
abline(v=val_index*600)

arima_pred3 <- xts(arima_pred3$mean, index(val))
```

```{r}
plot_pred(arima_pred3)

stats_results[nrow(stats_results) + 1,] <- c("arima_mod3", stats(val, arima_pred3))
```

#### Mod 4

```{r}
arima_mod4 <- function(train, train_dummy) {
  Arima(y = ts(train, freq = 144),
              order = c(0, 0, 0),
              seasonal = c(1, 0, 0),
              xreg = train_dummy,
              include.constant = FALSE)}
arima_mod4_train <- arima_mod4(train, train_dummy)
summary(arima_mod4_train)
```

```{r}
arima_pred4 <- forecast(arima_mod4_train,
                  144*npred,
                  xreg = val_dummy)
plot(arima_pred4)
abline(v=val_index*600)

arima_pred4 <- xts(arima_pred4$mean, index(val))
```

```{r}
plot_pred(arima_pred4)
stats_results[nrow(stats_results) + 1,] <- c("arima_mod4", stats(val, arima_pred4))
```

#### Mod 5

```{r}
train_meanhour <- period.apply(train, endpoints(train, "hours"), mean)
index(train_meanhour) <- index(train_meanhour)-600*2

train_byhour <- vector('list', 24)
for (hour in 1:24) {
  train_byhour[[hour]] <- train_meanhour[seq(hour, length(train_meanhour), 24)]
  }
```

```{r}
val_meanhour <- period.apply(val, endpoints(val, "hours"), mean)
index(val_meanhour) <- index(val_meanhour)-600*2

val_byhour <- vector('list', 24)
for (hour in 1:24) {
  val_byhour[[hour]] <- val_meanhour[seq(hour, length(val_meanhour), 24)] # to obtain the index
  }
```

```{r}
plot(train_byhour[[9]])

train_byhour[[9]] |> diff() |> Pacf()
```

```{r}
arima_mod5_byhour <- vector('list', 24)
for (hour in 1:24) {
  arima_mod5_byhour[[hour]] <- Arima(y = ts(train_byhour[[hour]], freq = 7),
                              order = c(0, 1, 1),
                              seasonal = c(0, 1, 1),
                              include.constant = FALSE
                              )
  }
```

```{r}
# auto arima
# mod5_byhour <- vector('list', 24)
# for (hour in 1:24) {
#   print(hour)
#   mod5_byhour[[hour]] <- auto.arima(y = ts(train_byhour[[hour]], freq = 7),
#                                     )
#   }
```

```{r}
arima_pred5_byhour <- vector('list', 24)
for (hour in 1:24) {
  arima_pred5_byhour[[hour]] <- forecast(arima_mod5_byhour[[hour]], npred)
  arima_pred5_byhour[[hour]] <- xts(arima_pred5_byhour[[hour]]$mean, index(val_byhour[[hour]]))
}

arima_pred5_merged <- do.call(rbind, arima_pred5_byhour) # concatenate the predictions
```

```{r}
temp <- xts(rep(as.numeric(NA), length(val)), index(val))
arima_pred5 <- merge(temp, arima_pred5_merged)$arima_pred5_merged
arima_pred5 <- na.approx(arima_pred5, na.rm = FALSE)
arima_pred5 <- na.locf(arima_pred5, na.rm = FALSE)
arima_pred5 <- na.locf(arima_pred5, fromLast = TRUE)
names(arima_pred5) <- "V1"
```

```{r}
arima_stats5_byhour <- vector('list', 24)
for (hour in 1:24) {
  arima_stats5_byhour[[hour]] <- stats(arima_pred5_byhour[[hour]], val_byhour[[hour]])[[3]]
}
plot(unlist(arima_stats5_byhour), type='l', ylab = 'MAE', xlab = 'Hour')
```

```{r}
plot_pred(arima_pred5)
stats_results[nrow(stats_results) + 1,] <- c("arima_mod5", stats(val, arima_pred5))
```

### UCM Models

Definisco il train set per i modelli ucm e una versione ridotta per velocizzare il train

```{r}
tseq <- seq(from = index(train[nrow(train),])+600,length.out = 144*npred,by = 600) # creo sequenza di NA a step di 10 min
train_ucm <- c(train, xts(rep(as.numeric(NA), length(tseq)), tseq)) # aggiungo NA a train
small_ucm <- c(small, xts(rep(as.numeric(NA), length(tseq)), tseq)) # aggiungo NA a small
```

#### Mod 1

```{r}
ucm_mod1 <- function(train) {
  # Definizione del modello
  mod <- SSModel(V1~SSMtrend(2, list(NA, NA))+
                    SSMseasonal(144, NA, "trigonometric", harmonics = 1:2)+
                    SSMseasonal(1008, NA, "trigonometric", harmonics = 1),
                  H=NA, 
                  data=train)

  # Assegna i valori iniziali ai parametri, parte da 0.
  mod$P1inf[] <- 0 # no componenti diffuse
  mod$a1[1] <- mean(log(train[1:144])) # scelta basata sui valori del primo mese
  
  vy <- var(log(train[1:144])) # varianza serie storica (utilizzata sotto per dare un ordine di grandezza)
  diag(mod$P1) <- vy*10 # specifichiamo che abbiamo molta incertezza sui valori che abbiamo specificato
  
  #Inizializzazione delle varianze sulla base di vy
  pars <- log(c(
    logVarEta = vy/100000,
    logVarZeta = vy/150,
    logVarOm144 = vy,
    logVarOm1008 = vy/100,
    logVarEps = vy/10
  ))
  
  # funzione di update
  updt <- function(pars, model){
    model$Q[1,1,1] <- exp(pars[1])
    model$Q[2,2,1] <- exp(pars[2])
    diag(model$Q[3:6, 3:6, 1]) <- exp(pars[3])
    diag(model$Q[7:8, 7:8, 1]) <- exp(pars[4])
    model$H[1,1,1] <- exp(pars[5])
    model
  }
  
  # Train - Si allena sui valori passati (quindi quei valori di train non nulli)
  fit <- fitSSM(mod, pars, updt)
  fit$optim.out
  
  # Filtro di karman - Effetua le predizioni - kfs1$muhat contiene una serie storica predetta (anche i dati di train vengono predetti)
  kfs <- KFS(fit$model,
            smoothing = c("state", "signal", "disturbance"))
  
  # conversione muhat in serie storica
  muhat <- xts(as.matrix(kfs$muhat),
                index(train))
  muhat <- as.xts(muhat)
  return(muhat)
}
```

```{r}
ucm_pred1 <- ucm_mod1(train_ucm)
```

```{r}
plot_pred(ucm_pred1)

ucm_stats1 <- stats(data_xts[val_index:(val_index+144*npred-1)], ucm_pred1[(nrow(ucm_pred1)-144*npred+1):nrow(ucm_pred1)])
stats_results[nrow(stats_results) + 1,] <- c("ucm_mod1", ucm_stats1)
```

#### Mod 2

```{r}
ucm_mod2 <- function(train) {
  arm144 <- 10
  arm1008 <- 1
  # Definizione del modello
  mod <- SSModel(V1~SSMtrend(2, list(NA, NA))+
                    SSMseasonal(144, NA, "trigonometric", harmonics = 1:arm144)+
                    SSMseasonal(1008, NA, "trigonometric", harmonics = 1:arm1008),
                  H=NA, 
                  data=train)

  # Assegna i valori iniziali ai parametri, parte da 0.
  mod$P1inf[] <- 0 # no componenti diffuse
  mod$a1[1] <- mean(train[1:144]) # expected value of the initial state vector α[1]
  
  vy <- var(train[1:144]) # varianza serie storica (utilizzata sotto per dare un ordine di grandezza)
  diag(mod$P1) <- vy*10 # specifichiamo che abbiamo molta incertezza sui valori che abbiamo specificato
  
  #Inizializzazione delle varianze sulla base di vy
  pars <- log(c(
    logVarEta = vy/10000,
    logVarZeta = vy/100000,
    logVarOm144 = vy/1000,
    logVarOm1008 = vy/100000,
    logVarEps = vy/1000
  ))
  
  # funzione di update
  updt <- function(pars, model){
    model$Q[1,1,1] <- exp(pars[1])
    model$Q[2,2,1] <- exp(pars[2])
    diag(model$Q[3:(2+arm144*2), 3:(2+arm144*2), 1]) <- exp(pars[3])
    diag(model$Q[(3+arm144*2):(2+arm144*2+arm1008*2), (3+arm144*2):(2+arm144*2+arm1008*2), 1]) <- exp(pars[4])
    model$H[1,1,1] <- exp(pars[5])
    model
  }
  
  # Train - Si allena sui valori passati (quindi quei valori di train non nulli)
  fit <- fitSSM(mod, pars, updt)
  print(fit$optim.out)
  
  # Filtro di karman - Effetua le predizioni - kfs1$muhat contiene una serie storica predetta (anche i dati di train vengono predetti)
  kfs <- KFS(fit$model,
            smoothing = c("state", "signal", "disturbance"))
  
  # conversione muhat in serie storica
  muhat <- xts(as.matrix(kfs$muhat),
                index(train))
  muhat <- as.xts(muhat)
  return(muhat)
}
```

```{r}
ucm_pred2 <- ucm_mod2(train_ucm)
```

```{r}
plot_pred(ucm_pred2)

ucm_stats2 <- stats(data_xts[val_index:(val_index+144*npred-1)], ucm_pred2[(nrow(ucm_pred2)-144*npred+1):nrow(ucm_pred2)])
stats_results[nrow(stats_results) + 1,] <- c("ucm_mod2", ucm_stats2)
```

Minimo

    RMSE 1718.399 
    MAPE 4.814626 
    MAE  1366.986

#### Mod 3

```{r}
ucm_mod3 <- function(train) {
  arm144 <- 10
  arm1008 <- 1
  # Definizione del modello
  mod <- SSModel(V1~SSMtrend(2, list(NA, NA))+
                    SSMseasonal(144, NA, "trigonometric", harmonics = 1:arm144)+
                    SSMseasonal(1008, NA, "trigonometric", harmonics = 1:arm1008),
                  H=NA, # Covariance matrix or array of disturbance terms ε[t] of observation equation
                  data=train)
  
  mod$P1inf[] <- 0 # diffuse part of P[1] (p[1] is the covariance matrix of α[1])
  mod$a1[1] <- mean(train[1:(144*3)]) # valore del livello iniziale (basata sulla media dei primi 3 giorni)
  vy <- var(log(train[1:(144)])) # varianza serie storica ((utilizzata sotto per dare un ordine di grandezza))primo giorno)
  diag(mod$P1) <- vy * 10 # specifichiamo che abbiamo molta incertezza sui valori che abbiamo specificato
  
  # definisco le varianze a partire da vy
  pars <- log(c(
    logVarEta = vy/100000,
    logVarZeta = vy/1500,
    logVarOm144 = vy/1,
    logVarOm1008 = vy/10000,
    logVarEps = vy/100
  ))
  
  # funzione di update -> imposto i valori iniziali
  updt <- function(pars, model){
    m <- arm144*2
    n <- arm1008*2
    model$Q[1,1,1] <- exp(pars[1])
    model$Q[2,2,1] <- exp(pars[2])
    diag(model$Q[3:(2+m), 3:(2+m), 1]) <- exp(pars[3])
    diag(model$Q[(3+m):(2+m+n), (3+m):(2+m+n), 1]) <- exp(pars[4])
    model$H[1,1,1] <- exp(pars[5])
    model
  }
  
  # Train - Si allena sui valori passati (quindi quei valori di train non nulli)
  fit <- fitSSM(mod, pars, updt)
  print(fit$optim.out)
  
  # Filtro di karman - Effetua le predizioni - kfs1$muhat contiene una serie storica predetta (anche i dati di train vengono predetti)
  kfs <- KFS(fit$model,
            smoothing = c("state", "signal", "disturbance"))
  
  # conversione muhat in serie storica
  muhat <- xts(as.matrix(kfs$muhat),
                index(train))
  muhat <- as.xts(muhat)
  return(muhat)
}
```

```{r}
ucm_pred3 <- ucm_mod3(train_ucm) # fare predizioni su 
```

```{r}
plot_pred(ucm_pred3)

ucm_stats3 <- stats(data_xts[val_index:(val_index+144*npred-1)], ucm_pred3[(nrow(ucm_pred3)-144*npred+1):nrow(ucm_pred3)])
stats_results[nrow(stats_results) + 1,] <- c("ucm_mod3", ucm_stats3)
```

### Machine Learning

La serie é abbastanza regolare quindi (a meno di eventi imprevedibili) le predizioni molto probabilemtne ircadono nel range dei valori passati e ne ricalcano i trend

#### Mod 1

```{r}
ml_mod1 <- function(train){
  knn_forecasting(ts(train),
                      h = 144*npred,
                      lags = 1:(144*7),
                      #k = 2,
                      msas = "MIMO",# cf = "median",
                      transform = "multiplicative")}
```

```{r}
ml_pred1 <- ml_mod1(train)
ml_pred1 <- xts(ml_pred1$prediction, index(val))
```

```{r}
plot_pred(ml_pred1)

stats_results[nrow(stats_results) + 1,] <- c("ml_mod1", stats(val, ml_pred1))
```

#### Mod 2

```{r}
ml_mod2 <- function(train){
  knn_forecasting(ts(train),
                      h = 144*npred,
                      lags = 1:(144),
                      #k = 2,
                      msas = "MIMO",# cf = "median",
                      transform = "multiplicative")}
```

```{r}
ml_pred2 <- ml_mod2(train)
ml_pred2 <- xts(ml_pred2$prediction, index(val))
```

```{r}
plot_pred(ml_pred2)
stats_results[nrow(stats_results) + 1,] <- c("ml_mod2", stats(val, ml_pred2))
```

## 3. Data prediction

```{r}
train_gen_nov <- data_xts_complete[1:(val_index+144*npred-1),]

# arima train
train_gen_nov_dummy <- fastDummies::dummy_cols(format(index(train_gen_nov), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(train_gen_nov_dummy) <- index(train_gen_nov)
colnames(train_gen_nov_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
train_gen_nov_dummy <- as.matrix(train_gen_nov_dummy)

test_gen_nov_dummy <- fastDummies::dummy_cols(format(index(test), "%u"), remove_selected_columns = TRUE, remove_first_dummy = TRUE)
rownames(test_gen_nov_dummy) <- index(test)
colnames(test_gen_nov_dummy) <- c("mart", "merc", "giov", "ven", "sab", "dom")
test_gen_nov_dummy <- as.matrix(test_gen_nov_dummy)

# ucm train
tseq <- seq(from = index(train_gen_nov[nrow(train_gen_nov),])+600, length.out = 144*npred, by = 600)
train_gen_nov_ucm <- c(train_gen_nov, xts(rep(as.numeric(NA), length(tseq)), tseq)) # aggiungo NA a train
```

```{r}
stats_results
```

#### ARIMA

```{r}
dic_arima_train <- arima_mod4(train_gen_nov, train_gen_nov_dummy)

dic_arima_pred <- forecast(dic_arima_train, 144*npred, xreg=test_gen_nov_dummy)
dic_arima_pred <- xts(dic_arima_pred$mean, index(val))
```

#### UCM

```{r}
dic_ucm <- ucm_mod2(train_gen_nov_ucm) # modello 1

dic_ucm_pred <- dic_ucm[(nrow(dic_ucm)-144*npred+1):nrow(dic_ucm)]
```

#### ML

```{r}
dic_ml <- ml_mod1(train_gen_nov)$prediction # modello 1

dic_ml_pred <- xts(dic_ml, index(test))
```

#### Results

```{r}
results <- data.frame(date = index(test),
                      ARIMA = dic_arima_pred,
                      UCM = dic_ucm_pred,
                      ML = dic_ml_pred)
```

```{r}
plot(results$ARIMA, type='l', col='red', lwd=2.5)
lines(results$UCM, col='blue', lwd=2.5)
lines(results$ML, col='green', lwd=2.5)

plot(results$ARIMA[(144*25):nrow(results)], type='l', col='red', lwd=2.5, ylim = c(20000, 43000))
lines(results$UCM[(144*25):nrow(results)], col='blue', lwd=2.5)
lines(results$ML[(144*25):nrow(results)], col='green', lwd=2.5)
```

```{r}
write.csv(results, "886725_20230205.csv", row.names=FALSE) # cambiare data
```
